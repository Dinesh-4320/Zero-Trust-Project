{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, StringIndexer\n",
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression, RandomForestClassifier, GBTClassifier, NaiveBayes, LinearSVC\n",
    ")\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score, roc_curve\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/27 18:02:44 WARN Utils: Your hostname, jayaraj-VMware-Virtual-Platform resolves to a loopback address: 127.0.1.1; using 192.168.3.128 instead (on interface ens33)\n",
      "24/12/27 18:02:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "24/12/27 18:02:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/27 18:03:05 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"FraudDetection_MultiModels\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "file_path = \"/home/jayaraj/Documents/Spark-VsCode/Fraud-Detection/dataset/spam.csv\" \n",
    "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "os.makedirs(\"output/visualizations\", exist_ok=True)\n",
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol=\"res\", outputCol=\"label\")\n",
    "data = indexer.fit(data).transform(data)\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"message\", outputCol=\"words\")\n",
    "data = tokenizer.transform(data)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=100)\n",
    "data = hashingTF.transform(data)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idf_model = idf.fit(data)\n",
    "data = idf_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to Train\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(featuresCol=\"features\", labelCol=\"label\"),\n",
    "    \"RandomForest\": RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\"),\n",
    "    \"GBTClassifier\": GBTClassifier(featuresCol=\"features\", labelCol=\"label\", maxIter=10),\n",
    "    \"NaiveBayes\": NaiveBayes(featuresCol=\"features\", labelCol=\"label\"),\n",
    "    \"LinearSVC\": LinearSVC(featuresCol=\"features\", labelCol=\"label\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# XGBoost requires NumPy arrays\n",
    "xgb_features = np.array(data.rdd.map(lambda row: row['features'].toArray()).collect())\n",
    "xgb_labels = np.array(data.rdd.map(lambda row: row['label']).collect())\n",
    "xgb_train = xgb.DMatrix(xgb_features, label=xgb_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results dictionary\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/27 18:05:51 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest...\n",
      "Training GBTClassifier...\n",
      "Training NaiveBayes...\n",
      "Training LinearSVC...\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    # Train the model\n",
    "    trained_model = model.fit(train_data)\n",
    "    predictions = trained_model.transform(test_data)\n",
    "\n",
    "    # Evaluate\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "    accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "    f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "    # Collect true labels and predictions for ROC curve\n",
    "    pred_and_labels = predictions.select(\"label\", \"prediction\").rdd.map(lambda row: (float(row[0]), float(row[1])))\n",
    "    labels = np.array([x[0] for x in pred_and_labels.collect()])\n",
    "    preds = np.array([x[1] for x in pred_and_labels.collect()])\n",
    "\n",
    "    roc_auc = roc_auc_score(labels, preds)\n",
    "    conf_matrix = confusion_matrix(labels, preds)\n",
    "\n",
    "    results[model_name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"conf_matrix\": conf_matrix\n",
    "    }\n",
    "\n",
    "    # Save confusion matrix\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, cmap=\"coolwarm\", fmt=\"d\", cbar=False,\n",
    "                xticklabels=[\"Normal\", \"Fraud\"], yticklabels=[\"Normal\", \"Fraud\"])\n",
    "    plt.title(f\"{model_name} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.savefig(f\"output/visualizations/{model_name}_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Save ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(labels, preds)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color=\"blue\", label=f\"AUC = {roc_auc:.2f}\")\n",
    "    plt.title(f\"{model_name} ROC Curve\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"output/visualizations/{model_name}_roc_curve.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayaraj/Documents/Spark-VsCode/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [18:06:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate XGBoost\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "xgb_model.fit(xgb_features, xgb_labels)\n",
    "xgb_preds = xgb_model.predict(xgb_features)\n",
    "\n",
    "# Evaluate XGBoost\n",
    "xgb_roc_auc = roc_auc_score(xgb_labels, xgb_preds)\n",
    "xgb_conf_matrix = confusion_matrix(xgb_labels, xgb_preds)\n",
    "\n",
    "results[\"XGBoost\"] = {\n",
    "    \"accuracy\": np.mean(xgb_preds == xgb_labels),\n",
    "    \"f1_score\": f1_score(xgb_labels, xgb_preds),\n",
    "    \"roc_auc\": xgb_roc_auc,\n",
    "    \"conf_matrix\": xgb_conf_matrix\n",
    "}\n",
    "\n",
    "# Save XGBoost confusion matrix and ROC curve\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(xgb_conf_matrix, annot=True, cmap=\"coolwarm\", fmt=\"d\", cbar=False,\n",
    "            xticklabels=[\"Normal\", \"Fraud\"], yticklabels=[\"Normal\", \"Fraud\"])\n",
    "plt.title(\"XGBoost Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.savefig(\"output/visualizations/XGBoost_confusion_matrix.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10841/3046150862.py:6: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=list(results.keys()), y=metric_values, palette=\"Blues_d\")\n",
      "/tmp/ipykernel_10841/3046150862.py:6: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=list(results.keys()), y=metric_values, palette=\"Blues_d\")\n",
      "/tmp/ipykernel_10841/3046150862.py:6: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=list(results.keys()), y=metric_values, palette=\"Blues_d\")\n"
     ]
    }
   ],
   "source": [
    "# Visualize Metrics Comparison\n",
    "metrics = [\"accuracy\", \"f1_score\", \"roc_auc\"]\n",
    "for metric in metrics:\n",
    "    metric_values = [results[model][metric] for model in results.keys()]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(x=list(results.keys()), y=metric_values, palette=\"Blues_d\")\n",
    "    plt.title(f\"{metric.capitalize()} Comparison\")\n",
    "    plt.xlabel(\"Models\")\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.savefig(f\"output/visualizations/{metric}_comparison.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "  accuracy: 0.7917\n",
      "  f1_score: 0.7992\n",
      "  roc_auc: 0.8303\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "  accuracy: 0.8333\n",
      "  f1_score: 0.8394\n",
      "  roc_auc: 0.8788\n",
      "\n",
      "\n",
      "Model: GBTClassifier\n",
      "  accuracy: 0.8333\n",
      "  f1_score: 0.8394\n",
      "  roc_auc: 0.8788\n",
      "\n",
      "\n",
      "Model: NaiveBayes\n",
      "  accuracy: 0.8958\n",
      "  f1_score: 0.8981\n",
      "  roc_auc: 0.9061\n",
      "\n",
      "\n",
      "Model: LinearSVC\n",
      "  accuracy: 0.8125\n",
      "  f1_score: 0.8191\n",
      "  roc_auc: 0.8455\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "  accuracy: 1.0000\n",
      "  f1_score: 1.0000\n",
      "  roc_auc: 1.0000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Results Summary\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    for metric, value in metrics.items():\n",
    "        if metric != \"conf_matrix\":\n",
    "            print(f\"  {metric}: {value:.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
